README.TXT
------------------------
This file lists the instructions to run the project BD_Assignment_5

----Author----
Sneha Bangar 

----Description----
Q1 - > This will output the business_id , full address and categories of the Top 10 highest rated businesses using the average ratings.
Q2 - > This will read a user name from the command line and find the average of their review rating.
Q3 - > This will list the 'user id' and 'stars' of users that reviewed businesses located in Stanford.
Q4 - > This is list the user_id , and name of the top 10 users who have written the most reviews.
Q5 - >This will list the business_id, and count of each business's ratings for the businesses that are located in the state of TX



---Library used---
	NA.
----Class Details----

1. Q1.Java & Q1.scala
   This is the class which runs a map reduce job to will output business_id, full_address and categories of the Top 10 highest rated businesses. This uses reduce side join.
    

2. Q2.Java & Q2.scala
   This is the class which read a user name from the command line and find the average of their review rating.

3. Q3.Java & Q3.scala
   This is the class which runs a map reduce job to list the 'user id' and 'stars' of users that reviewed businesses located in Stanford.
  
4. Q4.Java & Q4.scala
   This is the class which list the user_id , and name of the top 10 users who have written the most reviews.

5. Q5.Java
   This is the class which list the business_id, and count of each business's ratings for the businesses that are located in the state of TX


----Run in Command Line----
Command line run format to run on hdfs -
#Run Q1
A) Java
hadoop jar BD_Assignment_5-0.0.1-SNAPSHOT.jar BigData.BD_Assignment_5.Q1 <reviewfile.csv> <businessfile.csv> <outputlocation>

for example-
hadoop jar BD_Assignment_5-0.0.1-SNAPSHOT.jar BigData.BD_Assignment_5.Q1 /yelpdatafall/review/review.csv /yelpdatafall/business/business.csv hdfs://cshadoop1/user/ssb151030/asgn5_q1_op1

B) Spark scala
Copy content from Q1.scala and paste it on spark shell. Run using following command
Q1.main(null)

#Run Q2
A) Java
hadoop jar BD_Assignment_5-0.0.1-SNAPSHOT.jar BigData.BD_Assignment_5_Q2.Q2 <userfile.csv> <reviewfile.csv> <username> <outputlocation>

for example-
hadoop jar BD_Assignment_5-0.0.1-SNAPSHOT.jar BigData.BD_Assignment_5_Q2.Q2 /yelpdatafall/user/user.csv /yelpdatafall/review/review.csv 'Matt J.' hdfs://cshadoop1/user/ssb151030/asgn5_q2_op1

B) Spark scala
Copy content from Q2.scala and paste it on spark shell. Run using following command
Q2.main(Array("Matt J."))

#Run Q3
A) Java
hadoop jar BD_Assignment_5-0.0.1-SNAPSHOT.jar BigData.BD_Assignment_5_Q3.Q3 <businessfile.csv> <reviewfile.csv> <outputlocation>

for example-
hadoop jar BD_Assignment_5-0.0.1-SNAPSHOT.jar BigData.BD_Assignment_5_Q3.Q3 /yelpdatafall/business/business.csv /yelpdatafall/review/review.csv hdfs://cshadoop1/user/ssb151030/asgn5_q3_op1

B) Spark scala
Copy content from Q3.scala and paste it on spark shell. Run using following command
Q3.main(null)

#Run Q4
A) Java
hadoop jar BD_Assignment_5-0.0.1-SNAPSHOT.jar BigData.BD_Assignment_5_Q4.Q4 <reviewfile.csv> <userfile.csv> <outputlocation>

for example-
hadoop jar BD_Assignment_5-0.0.1-SNAPSHOT.jar BigData.BD_Assignment_5_Q4.Q4 /yelpdatafall/review/review.csv /yelpdatafall/user/user.csv hdfs://cshadoop1/user/ssb151030/asgn5_q4_op1

B) Spark scala
Copy content from Q3.scala and paste it on spark shell. Run using following command
Q4.main(null)

#Run Q5
A) Java
hadoop jar BD_Assignment_5-0.0.1-SNAPSHOT.jar BigData.BD_Assignment_5_Q5.Q5 <businessfile.csv> <reviewfile.csv> <outputlocation>

for example-
hadoop jar BD_Assignment_5-0.0.1-SNAPSHOT.jar BigData.BD_Assignment_5_Q5.Q5 /yelpdatafall/business/business.csv /yelpdatafall/review/review.csv hdfs://cshadoop1/user/ssb151030/asgn5_q5_op1

B) Spark scala
Copy content from Q3.scala and paste it on spark shell. Run using following command
Q5.main(null)


---Results----
I have included the outputs generated by map reduce job for Q1, Q2 and Q4. Q3 and Q5 output files were larger hence not included.
